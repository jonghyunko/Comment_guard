{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1H56uLZ7x3-SJjwnaUTqt5jrl3Z-uTgiJ","authorship_tag":"ABX9TyOFLLcu5xpU49HcNy2Fw0is"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSKDR9QhzJty","executionInfo":{"status":"ok","timestamp":1701676137438,"user_tz":-540,"elapsed":18383,"user":{"displayName":"종현","userId":"00841649676888510360"}},"outputId":"8549518b-a65a-4d76-afce-fafd3263a178"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn, optim\n","from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"eGPLwGZqznlA","executionInfo":{"status":"ok","timestamp":1701677301583,"user_tz":-540,"elapsed":2054,"user":{"displayName":"종현","userId":"00841649676888510360"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")"],"metadata":{"id":"5t9X708F1vqk","executionInfo":{"status":"ok","timestamp":1701677307948,"user_tz":-540,"elapsed":789,"user":{"displayName":"종현","userId":"00841649676888510360"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/NLP_commit/Comment_guard/unsmile_train_v1.0.tsv', delimiter='\\t')\n","valid_df = pd.read_csv('/content/drive/MyDrive/NLP_commit/Comment_guard/unsmile_valid_v1.0.tsv', delimiter='\\t')"],"metadata":{"id":"ZenaRWQS0sKG","executionInfo":{"status":"ok","timestamp":1701676793681,"user_tz":-540,"elapsed":405,"user":{"displayName":"종현","userId":"00841649676888510360"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# '문장' 열과 레이블 생성 (0: 부정적인 문장)\n","train_sentences = train_df['문장']\n","train_labels = torch.zeros(len(train_df), dtype=torch.long)\n","\n","valid_sentences = valid_df['문장']\n","valid_labels = torch.zeros(len(valid_df), dtype=torch.long)\n"],"metadata":{"id":"KXIMlARf0tsI","executionInfo":{"status":"ok","timestamp":1701677400164,"user_tz":-540,"elapsed":5,"user":{"displayName":"종현","userId":"00841649676888510360"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 문장을 토크나이저로 변환하여 패딩 적용하는 함수 정의\n","def tokenize_sentences(sentences, max_length=50):\n","    tokens = tokenizer(sentences.tolist(), padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n","    return tokens"],"metadata":{"id":"sW_EISR31JZA","executionInfo":{"status":"ok","timestamp":1701677412548,"user_tz":-540,"elapsed":7,"user":{"displayName":"종현","userId":"00841649676888510360"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# 훈련 데이터와 검증 데이터 전처리\n","train_tokens = tokenize_sentences(train_sentences)\n","valid_tokens = tokenize_sentences(valid_sentences)"],"metadata":{"id":"lVUhacHd1XXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_tokens)\n","print(valid_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xNsxM8414m-","executionInfo":{"status":"ok","timestamp":1701676816114,"user_tz":-540,"elapsed":12,"user":{"displayName":"종현","userId":"00841649676888510360"}},"outputId":"e516995e-c1f9-4112-805a-50b0a769e875"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[2, 0, 0,  ..., 1, 1, 1],\n","        [2, 0, 0,  ..., 1, 1, 1],\n","        [2, 0, 0,  ..., 1, 1, 1],\n","        ...,\n","        [2, 0, 0,  ..., 1, 1, 1],\n","        [2, 0, 0,  ..., 1, 1, 1],\n","        [2, 0, 0,  ..., 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])}\n","{'input_ids': tensor([[   2,    0, 7347,  ...,    1,    1,    1],\n","        [   2,    0,    0,  ...,    1,    1,    1],\n","        [   2,    0, 5782,  ...,    1,    1,    1],\n","        ...,\n","        [   2,    0,    0,  ...,    1,    1,    1],\n","        [   2,  497,    0,  ...,    1,    1,    1],\n","        [   2,    0,    0,  ...,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rKwC64pn17La"},"execution_count":null,"outputs":[]}]}